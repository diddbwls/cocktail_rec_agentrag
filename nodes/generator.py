from typing import Dict, Any, List
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from utils.openai_client import OpenAIClient
from utils.prompt_loader import PromptLoader

def format_system_analysis_info(task_type: str, task_confidence: float, task_reason: str,
                               final_best_round: int, final_best_score: float, 
                               final_best_top_k: int, cocktails_count: int,
                               evaluation_scores: Dict[str, float], 
                               reflection_feedback: str) -> str:
    """
    ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…
    
    Args:
        task_type: ë¶„ë¥˜ëœ íƒœìŠ¤í¬ íƒ€ì…
        task_confidence: ë¶„ë¥˜ ì‹ ë¢°ë„
        task_reason: ë¶„ë¥˜ ì´ìœ 
        final_best_round: ì„ íƒëœ ë¼ìš´ë“œ
        final_best_score: ìµœê³  ì ìˆ˜
        final_best_top_k: ì„ íƒëœ ë•Œì˜ Top-K
        cocktails_count: ì¶”ì²œëœ ì¹µí…Œì¼ ìˆ˜
        evaluation_scores: í‰ê°€ ì ìˆ˜ë“¤
        reflection_feedback: ë¦¬í”Œë ‰ì…˜ í”¼ë“œë°±
        
    Returns:
        í¬ë§·ëœ ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´ í…ìŠ¤íŠ¸
    """
    # íƒœìŠ¤í¬ íƒ€ì…ë³„ ì´ë¦„ ë§¤í•‘
    task_names = {
        "C1": "ìƒ‰ìƒ-ì¬ë£Œ ê¸°ë°˜ ì‹œê° ê²€ìƒ‰",
        "C2": "ê¸€ë¼ìŠ¤ íƒ€ì… + ì¬ë£Œ ë§¤ì¹­", 
        "C3": "Multi-hop ì¬ë£Œ í™•ì¥ ê²€ìƒ‰",
        "C4": "ì¹µí…Œì¼ ìœ ì‚¬ë„ ë° ëŒ€ì•ˆ ì¶”ì²œ"
    }
    
    task_name = task_names.get(task_type, task_type)
    
    # ë¶„ë¥˜ ì •ë³´
    classification_info = f"""ğŸ¯ íƒœìŠ¤í¬ ë¶„ë¥˜:
- ë¶„ë¥˜ ê²°ê³¼: {task_type} ({task_name})
- ì‹ ë¢°ë„: {task_confidence:.1f}%
- ë¶„ë¥˜ ì´ìœ : {task_reason}"""
    
    # ì„ íƒ ì •ë³´ - ë¼ìš´ë“œë³„ ìƒí™© ì„¤ëª…
    if final_best_round == 1:
        selection_reason = "ì²« ë²ˆì§¸ ê²€ìƒ‰ì—ì„œ ì¶©ë¶„í•œ í’ˆì§ˆ ë‹¬ì„±"
    elif final_best_score >= 80:
        selection_reason = f"Round {final_best_round}ì—ì„œ í’ˆì§ˆ ê¸°ì¤€(80ì ) ë‹¬ì„±"
    else:
        selection_reason = f"3íšŒ ë°˜ë³µ ì¤‘ Round {final_best_round}ì—ì„œ ìµœê³  í’ˆì§ˆ ë‹¬ì„±"
    
    selection_info = f"""ğŸ† ìµœì¢… ì„ íƒ:
- ì„ íƒëœ ë¼ìš´ë“œ: Round {final_best_round}
- ì¶”ì²œ ì¹µí…Œì¼ ìˆ˜: {cocktails_count}ê°œ (Top-{final_best_top_k} ê²€ìƒ‰)
- í’ˆì§ˆ ì ìˆ˜: {final_best_score:.1f}/100ì 
- ì„ íƒ ì´ìœ : {selection_reason}"""
    
    # í‰ê°€ ì ìˆ˜ - ë” ìƒì„¸í•œ ì„¤ëª…
    if evaluation_scores:
        try:
            relevance = float(evaluation_scores.get('relevance', 0))
            diversity = float(evaluation_scores.get('diversity', 0))
            completeness = float(evaluation_scores.get('completeness', 0))
            coherence = float(evaluation_scores.get('coherence', 0))
            
            evaluation_info = f"""ğŸ“Š í’ˆì§ˆ í‰ê°€ ì„¸ë¶€ ì ìˆ˜:
- ê´€ë ¨ì„± (Relevance): {relevance:.1f}/100ì  - ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„±
- ë‹¤ì–‘ì„± (Diversity): {diversity:.1f}/100ì  - ì¶”ì²œì˜ ë‹¤ì–‘ì„±
- ì™„ì „ì„± (Completeness): {completeness:.1f}/100ì  - ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„
- ì¼ê´€ì„± (Coherence): {coherence:.1f}/100ì  - ë…¼ë¦¬ì  ì¼ê´€ì„±
- ì „ì²´ ì ìˆ˜: {final_best_score:.1f}/100ì 

ğŸ’¡ ì‹œìŠ¤í…œ í”¼ë“œë°±: {reflection_feedback}"""
        except (ValueError, TypeError):
            evaluation_info = f"""ğŸ“Š í’ˆì§ˆ í‰ê°€:
- ì „ì²´ ì ìˆ˜: {final_best_score:.1f}/100ì 
- í”¼ë“œë°±: {reflection_feedback}"""
    else:
        evaluation_info = f"""ğŸ“Š í’ˆì§ˆ í‰ê°€:
- ì „ì²´ ì ìˆ˜: {final_best_score:.1f}/100ì """
    
    return f"""
{classification_info}

{selection_info}

{evaluation_info}
"""

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAIClient()
prompt_loader = PromptLoader()

def format_cocktails_for_response(cocktails: List[Dict[str, Any]]) -> str:
    """
    ì¹µí…Œì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìµœì¢… ì‘ë‹µìš©ìœ¼ë¡œ í¬ë§·íŒ…
    
    Args:
        cocktails: ì¹µí…Œì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í¬ë§·ëœ í…ìŠ¤íŠ¸
    """
    if not cocktails:
        return "ì¶”ì²œí•  ì¹µí…Œì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    formatted_lines = []
    
    for i, cocktail in enumerate(cocktails, 1):
        name = cocktail.get('name', 'Unknown')
        category = cocktail.get('category', 'N/A')
        glass_type = cocktail.get('glassType', 'N/A')
        alcoholic = cocktail.get('alcoholic', 'N/A')
        description = cocktail.get('description', '')
        instructions = cocktail.get('instructions', '')
        
        # í—¤ë”
        formatted_lines.append(f"{i}. **{name}**")
        formatted_lines.append(f"   - ì¹´í…Œê³ ë¦¬: {category}")
        formatted_lines.append(f"   - ê¸€ë¼ìŠ¤ íƒ€ì…: {glass_type}")
        formatted_lines.append(f"   - ì•Œì½”ì˜¬: {alcoholic}")
        
        # ì¬ë£Œ ì •ë³´
        recipe_ingredients = cocktail.get('recipe_ingredients', [])
        ingredients = cocktail.get('ingredients', [])
        
        if recipe_ingredients:
            formatted_lines.append("   - ì¬ë£Œ:")
            for ingredient_info in recipe_ingredients:
                measure = ingredient_info.get('measure', 'unknown')
                ingredient = ingredient_info.get('ingredient', 'unknown')
                formatted_lines.append(f"     â€¢ {measure} {ingredient}")
        elif ingredients:
            formatted_lines.append(f"   - ì¬ë£Œ: {', '.join(ingredients)}")
        
        # ì œì¡°ë²•
        if instructions:
            formatted_lines.append(f"   - ì œì¡°ë²•: {instructions}")
            
        # ì„¤ëª…
        if description:
            formatted_lines.append(f"   - ì„¤ëª…: {description}")
        
        formatted_lines.append("")  # ë¹ˆ ì¤„
    
    return "\n".join(formatted_lines)

def generate_final_response(user_query: str, cocktails: List[Dict[str, Any]], 
                          task_type: str, evaluation_scores: Dict[str, float],
                          reflection_feedback: str, task_confidence: float = 0,
                          task_reason: str = "", final_best_round: int = 1,
                          final_best_score: float = 0, final_best_top_k: int = 3) -> str:
    """
    ìµœì¢… ì‘ë‹µ ìƒì„±
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        cocktails: ì¶”ì²œ ì¹µí…Œì¼ ë¦¬ìŠ¤íŠ¸
        task_type: íƒœìŠ¤í¬ íƒ€ì… (C1-C4)
        evaluation_scores: í‰ê°€ ì ìˆ˜ë“¤
        reflection_feedback: ë¦¬í”Œë ‰ì…˜ í”¼ë“œë°±
        
    Returns:
        ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    try:
        # íƒœìŠ¤í¬ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        task_prompt = prompt_loader.get_task_prompt(task_type)
        
        # ì¹µí…Œì¼ ì •ë³´ í¬ë§·íŒ…
        cocktails_context = format_cocktails_for_response(cocktails)
        
        # í‰ê°€ ì •ë³´ í¬ë§·íŒ…
        evaluation_text = ""
        if evaluation_scores:
            # ê° ì ìˆ˜ë¥¼ floatë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ê³„ì‚°
            try:
                relevance = float(evaluation_scores.get('relevance', 0))
                diversity = float(evaluation_scores.get('diversity', 0))
                completeness = float(evaluation_scores.get('completeness', 0))
                coherence = float(evaluation_scores.get('coherence', 0))
                
                overall_score = (relevance + diversity + completeness + coherence) / 4
                
                evaluation_text = f"""
í‰ê°€ ì ìˆ˜:
- ê´€ë ¨ì„±: {relevance:.1f}ì 
- ë‹¤ì–‘ì„±: {diversity:.1f}ì   
- ì™„ì „ì„±: {completeness:.1f}ì 
- ì¼ê´€ì„±: {coherence:.1f}ì 
- ì „ì²´: {overall_score:.1f}ì 

{reflection_feedback}
"""
            except (ValueError, TypeError) as e:
                print(f"âš ï¸ í‰ê°€ ì ìˆ˜ ë³€í™˜ ì˜¤ë¥˜: {e}")
                evaluation_text = f"""
í‰ê°€ ì ìˆ˜ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ì›ë³¸ ë°ì´í„°: {evaluation_scores}

{reflection_feedback}
"""
        
        # í”„ë¡¬í”„íŠ¸ì— ì •ë³´ ì‚½ì…
        prompt = task_prompt.format(
            question=user_query,
            context=cocktails_context
        )
        
        # ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´ ìƒì„±
        system_analysis = format_system_analysis_info(
            task_type=task_type,
            task_confidence=task_confidence,
            task_reason=task_reason,
            final_best_round=final_best_round,
            final_best_score=final_best_score,
            final_best_top_k=final_best_top_k,
            cocktails_count=len(cocktails),
            evaluation_scores=evaluation_scores,
            reflection_feedback=reflection_feedback
        )

        # ì¶”ê°€ ì§€ì‹œì‚¬í•­ í¬í•¨
        enhanced_prompt = f"""{prompt}

---
ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´:
{system_analysis}
---

ìœ„ì˜ ì¹µí…Œì¼ ì •ë³´ì™€ ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì¹µí…Œì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ì¶”ì²œ ì´ìœ , ë§›ì˜ íŠ¹ì§•, ìƒí™©ë³„ ì¶”ì²œ ë“±ì„ í¬í•¨í•˜ì—¬ ì„¤ëª…í•˜ê³ , ë‹µë³€ ë§ˆì§€ë§‰ì— "ğŸ“‹ ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´" ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ìœ„ì˜ ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”."""

        print(f"ğŸ¯ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘... ({task_type})")
        
        # OpenAI API í˜¸ì¶œ
        response = openai_client.generate(enhanced_prompt, max_tokens=1500)
        
        return response
        
    except Exception as e:
        print(f"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        cocktails_text = format_cocktails_for_response(cocktails)
        return f"""ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì¹µí…Œì¼ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤:

{cocktails_text}

ì˜¤ë¥˜ ë‚´ìš©: {str(e)}"""

def generator(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¹„êµìš© ì‘ë‹µì„ ìƒì„±í•˜ëŠ” Generator ë…¸ë“œ
    
    ì´ˆê¸° ë‹µë³€ê³¼ ìµœì¢… ë‹µë³€ì„ ê°ê° ìƒì„±í•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        state: íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì´ˆê¸° ë‹µë³€ê³¼ ìµœì¢… ë‹µë³€ì´ í¬í•¨ëœ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
    """
    # í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    user_query = state.get("input_text_with_image", state.get("input_text", ""))
    task_type = state.get("task_type", "C1")
    iteration_count = state.get("iteration_count", 0)
    
    print(f"\nğŸ“ ë¹„êµìš© ì‘ë‹µ ìƒì„± ì‹œì‘ ({task_type}, {iteration_count}íšŒ ë°˜ë³µ)")
    
    # 1. ì´ˆê¸° ë‹µë³€ ìƒì„± (Round 1 ê²°ê³¼ ì‚¬ìš©)
    initial_results = state.get("initial_search_results", [])
    if initial_results:
        print(f"ğŸ¥‰ ì´ˆê¸° ë‹µë³€ ìƒì„± ì¤‘... ({len(initial_results)}ê°œ ì¹µí…Œì¼)")
        try:
            # íƒœìŠ¤í¬ ë¶„ë¥˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            task_confidence = state.get("task_confidence", 0)
            task_reason = state.get("task_reason", "ì •ë³´ ì—†ìŒ")
            
            # ì´ˆê¸° í‰ê°€ ì ìˆ˜ ì‚¬ìš© (reflectionì—ì„œ ì €ì¥í•œ ê²ƒ)
            initial_evaluation_scores = state.get("initial_evaluation_scores", {})
            initial_score = state.get("initial_score", 0)
            initial_feedback = state.get("initial_feedback", "ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼")
            
            print(f"ğŸ” ì´ˆê¸° í‰ê°€ ì ìˆ˜ í™•ì¸:")
            print(f"   - initial_evaluation_scores: {initial_evaluation_scores}")
            print(f"   - initial_score: {initial_score}")
            print(f"   - initial_feedback: {initial_feedback}")
            
            initial_response = generate_final_response(
                user_query=user_query,
                cocktails=initial_results,
                task_type=task_type,
                evaluation_scores=initial_evaluation_scores,
                reflection_feedback=initial_feedback,
                task_confidence=task_confidence,
                task_reason=task_reason,
                final_best_round=1,
                final_best_score=initial_score,
                final_best_top_k=len(initial_results)
            )
            state["initial_response"] = initial_response
            print(f"âœ… ì´ˆê¸° ë‹µë³€ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì´ˆê¸° ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            state["initial_response"] = f"ì´ˆê¸° ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # 2. ìµœì¢… ë‹µë³€ ìƒì„± (ìµœê³  ì ìˆ˜ ë¼ìš´ë“œ ê²°ê³¼ ì‚¬ìš©)
    final_results = state.get("final_search_results", [])
    if final_results:
        final_best_round = state.get("final_best_round", 3)
        final_best_score = state.get("final_best_score", 0)
        final_best_top_k = state.get("final_best_top_k", len(final_results))
        
        print(f"ğŸ† ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘... (Round {final_best_round}, {len(final_results)}ê°œ ì¹µí…Œì¼, {final_best_score:.1f}ì )")
        
        evaluation_scores = state.get("evaluation_scores", {})
        reflection_feedback = state.get("reflection_feedback", "")
        
        try:
            # íƒœìŠ¤í¬ ë¶„ë¥˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            task_confidence = state.get("task_confidence", 0)
            task_reason = state.get("task_reason", "ì •ë³´ ì—†ìŒ")
            
            final_response = generate_final_response(
                user_query=user_query,
                cocktails=final_results,
                task_type=task_type,
                evaluation_scores=evaluation_scores,
                reflection_feedback=reflection_feedback,
                task_confidence=task_confidence,
                task_reason=task_reason,
                final_best_round=final_best_round,
                final_best_score=final_best_score,
                final_best_top_k=final_best_top_k
            )
            state["final_response"] = final_response
            state["final_text"] = final_response  # í•˜ìœ„ í˜¸í™˜ì„±
            state["final_cocktails"] = final_results  # í•˜ìœ„ í˜¸í™˜ì„±
            print(f"âœ… ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ìµœì¢… ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            state["final_response"] = f"ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            state["final_text"] = f"ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            state["final_cocktails"] = final_results
    
    # 3. ì‘ë‹µì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
    if not initial_results and not final_results:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
        error_response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. "{user_query}"ì— ëŒ€í•œ ì ì ˆí•œ ì¹µí…Œì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ë‹¤ì‹œ í•œë²ˆ ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ ì„¤ëª…ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜, ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”:
- ì„ í˜¸í•˜ëŠ” ìƒ‰ìƒì´ë‚˜ ë§›
- íŠ¹ì • ì¬ë£Œë‚˜ ë² ì´ìŠ¤ ìˆ 
- ë§ˆì‹œê³  ì‹¶ì€ ìƒí™©ì´ë‚˜ ë¶„ìœ„ê¸°
- ê¸€ë¼ìŠ¤ íƒ€ì…ì´ë‚˜ ìŠ¤íƒ€ì¼"""
        
        state["initial_response"] = error_response
        state["final_response"] = error_response
        state["final_text"] = error_response
        state["final_cocktails"] = []
    
    # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
    if "debug_info" not in state:
        state["debug_info"] = {}
    
    state["debug_info"]["generation"] = {
        "task_type": task_type,
        "initial_cocktails_count": len(initial_results),
        "final_cocktails_count": len(final_results),
        "initial_response_length": len(state.get("initial_response", "")),
        "final_response_length": len(state.get("final_response", "")),
        "iteration_count": iteration_count,
        "final_best_round": state.get("final_best_round", 0),
        "final_best_score": state.get("final_best_score", 0),
        "final_best_top_k": state.get("final_best_top_k", 0)
    }
    
    return state