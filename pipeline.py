from langgraph.graph import StateGraph, START, END
from nodes.task_classifier import query_classification
from nodes.retriever import graph_query_node, incremental_retriever
from nodes.reflection import reflection
from nodes.generator import generator
from utils.types import PipelineState
from typing import Dict, Any, Literal
from nodes.user_question import initial_query


def build_pipeline_graph() -> StateGraph:
    """
    LangGraph íŒŒì´í”„ë¼ì¸ êµ¬ì„±
    
    í”Œë¡œìš°:
    START â†’ user_question â†’ task_classification â†’ retriever (Round 1) â†’ reflection â†’ [ì¡°ê±´ë¶€ ë¶„ê¸°]
                                                        â†“
    generator â† [80ì  ì´ìƒ or 3íšŒ ë°˜ë³µ] â† reflection â† incremental_retriever (Round 2,3) â† [80ì  ë¯¸ë§Œ & 3íšŒ ë¯¸ë§Œ]
        â†“
       END
    """
    graph = StateGraph(PipelineState)
    
    # ë…¸ë“œ ì •ì˜
    graph.add_node("task_classification", query_classification)
    graph.add_node("user_question", initial_query)
    graph.add_node("retriever", graph_query_node)  # ì´ˆê¸° ê²€ìƒ‰ (Round 1)
    graph.add_node("incremental_retriever", incremental_retriever)  # ì¦ë¶„ ê²€ìƒ‰ (Round 2, 3)
    graph.add_node("reflection", reflection)
    graph.add_node("generator", generator)
    
    # ê¸°ë³¸ í”Œë¡œìš°
    graph.add_edge(START, "user_question")  # Updated edge name
    graph.add_edge("user_question", "task_classification")  # Updated edge name
    graph.add_edge("task_classification", "retriever")  # Round 1: ì´ˆê¸° ê²€ìƒ‰
    graph.add_edge("retriever", "reflection")
    graph.add_edge("incremental_retriever", "reflection")  # Round 2, 3: ì¦ë¶„ ê²€ìƒ‰ í›„ reflection
    
    # Reflectionì—ì„œ ì¡°ê±´ë¶€ ë¶„ê¸°
    def reflection_condition(state: Dict[str, Any]) -> Literal["score<80", "score>=80"]:
        """
        Reflection ê²°ê³¼ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
        
        Args:
            state: íŒŒì´í”„ë¼ì¸ ìƒíƒœ
            
        Returns:
            "score<80": incremental_retrieverë¡œ ì¬ì‹œë„ (Round 2, 3)
            "score>=80": generatorë¡œ ì¢…ë£Œ
        """
        # Handle missing 'should_retry' field
        if "should_retry" not in state:
            state["should_retry"] = False
            
        should_retry = state.get("should_retry", False)
        score = state.get("score", 0)
        iteration_count = state.get("iteration_count", 0)
        
        # ë¡œê·¸ ì¶œë ¥
        print(f"ğŸ”€ ì¡°ê±´ë¶€ ë¶„ê¸° íŒë‹¨:")
        print(f"   - ì ìˆ˜: {score:.1f}")
        print(f"   - ë°˜ë³µ íšŸìˆ˜: {iteration_count}/3")
        print(f"   - ì¬ì‹œë„ í•„ìš”: {should_retry}")
        
        if should_retry:
            print("   â†’ ì¬ì‹œë„: incremental_retrieverë¡œ ì´ë™")
            return "score<80"
        else:
            print("   â†’ ì™„ë£Œ: generatorë¡œ ì´ë™")
            return "score>=80"
    
    # ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
    graph.add_conditional_edges(
        "reflection",
        reflection_condition,
        {
            "score<80": "incremental_retriever",    # ì¦ë¶„ ê²€ìƒ‰ìœ¼ë¡œ ì¬ì‹œë„
            "score>=80": "generator"                   # ì™„ë£Œ
        }
    )
    
    # ìµœì¢… ì¶œë ¥
    graph.add_edge("generator", END)
    
    return graph

def save_workflow_diagram():
    """ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì„ PNGë¡œ ì €ì¥"""
    try:
        import os
        from langchain_core.runnables.graph_mermaid import MermaidDrawMethod
        
        # ì›Œí¬í”Œë¡œìš° ìƒì„±
        app = build_pipeline_graph().compile()
        
        # graph_viz ë””ë ‰í† ë¦¬ ìƒì„± (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        viz_dir = "./langgraph/graph_viz"
        os.makedirs(viz_dir, exist_ok=True)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ë° ì €ì¥
        diagram_path = os.path.join(viz_dir, "workflow.png")
        
        print("ğŸ”„ ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì¤‘...")
        
        # Mermaid ì½”ë“œ ê°€ì ¸ì™€ì„œ ìˆ˜ì •
        mermaid_code = app.get_graph().draw_mermaid()
        
        # reflection -> generator ì—£ì§€ë¥¼ ì ì„ ì—ì„œ ì‹¤ì„ ìœ¼ë¡œ ë³€ê²½ (ë¼ë²¨ ìœ ì§€)
        mermaid_code = mermaid_code.replace(
            "reflection -. &nbsp;score>=80&nbsp; .-> generator;",
            "reflection --&nbsp;score>=80&nbsp;--> generator;"
        )
        
        # ë°©ë²• 1: pyppeteer ë¡œì»¬ ë Œë”ë§ (ìš°ì„  ì‹œë„)
        try:
            print("  ğŸŒ ë°©ë²• 1: ë¡œì»¬ ë¸Œë¼ìš°ì € ë Œë”ë§")
            # ìˆ˜ì •ëœ mermaid ì½”ë“œë¡œ PNG ìƒì„±
            from langchain_core.runnables.graph_mermaid import draw_mermaid_png
            graph_image = draw_mermaid_png(
                mermaid_code,
                draw_method=MermaidDrawMethod.PYPPETEER,
                max_retries=3,
                retry_delay=1.0
            )
            with open(diagram_path, 'wb') as f:
                f.write(graph_image)
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤ (ë¡œì»¬ ë Œë”ë§): {diagram_path}")
            return
            
        except Exception as local_error:
            print(f"  âš ï¸ ë¡œì»¬ ë Œë”ë§ ì‹¤íŒ¨: {local_error}")
            
            # ë°©ë²• 2: API ë Œë”ë§ (fallback)
            try:
                print("  ğŸ“¡ ë°©ë²• 2: mermaid.ink API")
                graph_image = app.get_graph().draw_mermaid_png(
                    max_retries=5,
                    retry_delay=2.0
                )
                with open(diagram_path, 'wb') as f:
                    f.write(graph_image)
                print(f"âœ… ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤ (API): {diagram_path}")
                return
                
            except Exception as api_error:
                print(f"  âŒ API ë°©ë²•ë„ ì‹¤íŒ¨: {api_error}")
                raise Exception(f"Local: {local_error}\nAPI: {api_error}")
        
    except Exception as e:
        print(f"âŒ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì‹¤íŒ¨: {e}")
        
def run_pipeline(user_query: str, image_path: str = None) -> Dict[str, Any]:
    """
    íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        
    Returns:
        ì‹¤í–‰ ê²°ê³¼ê°€ í¬í•¨ëœ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
    """
    # íŒŒì´í”„ë¼ì¸ ê·¸ë˜í”„ ìƒì„±
    graph = build_pipeline_graph()
    app = graph.compile()
    
    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = {
        "user_query": {
            "text": user_query,
            "image": image_path
        },
        "input_text": user_query,
        "input_image": image_path,
        "current_top_k": 3,
        "iteration_count": 0,
        "debug_info": {}
    }
    
    print(f"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"ğŸ“ ì§ˆë¬¸: {user_query}")
    if image_path:
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: {image_path}")
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = app.invoke(initial_state)
        
        print(f"âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return result
        
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            "final_text": f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "final_cocktails": [],
            "error": str(e)
        }

if __name__ == "__main__":
    
    #  ì‹¤í–‰ ì˜µì…˜
    
    # Option 1: íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # test_pipeline()
    
    # Option 2: ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ PNG ìƒì„±
    save_workflow_diagram()
    
    # Option 3: ì»¤ìŠ¤í…€ ì¿¼ë¦¬ë¡œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    # custom_query = "your query here"
    # result = run_pipeline(custom_query)
    # print(f"\nìµœì¢… ê²°ê³¼: {result.get('final_text', 'ì‘ë‹µ ì—†ìŒ')}")
    
